# Serverless-LLM-apps-with-Amazon-Bedrock
Learn how to deploy a large language model-based application into production using serverless technology.

## Workflow
1. Learn how to prompt and customize your LLM responses using Amazon Bedrock.
2. Summarize audio conversations by first transcribing an audio file and passing the transcription to an LLM.
3. Deploy an event-driven audio summarizer that runs as new audio files are uploaded; using a serverless architecture.
